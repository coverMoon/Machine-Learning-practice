# 机器学习练习
---

本仓库主要存放周志华《机器学习》一书的课后题练习代码，使用 python 编写

---

### 对数几率回归

存放在`logistic_regression`目录中，手动实现梯度下降、损失函数

* **当前结果**: 模型成功学习到了一条线性的决策边界。但从可视化结果来看，该直线无法完美地将两类西瓜样本分开，存在一定的误分类。 

* **原因分析**: 这表明西瓜数据集很可能是一个**非线性可分**的问题，而对数几率回归作为一种线性模型，其表达能力有限。

* **后续改进方向**:    

  - **特征工程**: 为模型增加多项式特征（如密度的平方、含糖率的平方、两者之积等），使线性模型能够学习到非线性的决策边界。   

  - **采用非线性模型**: 尝试使用更强大的模型，如支持向量机（SVM）的核技巧、决策树、随机森林或神经网络等。

### 线性判别分析 (LDA)

存放在`linear_discriminant_analysis`目录中，从零开始手动实现了算法的核心步骤，包括均值向量、类内/类间散度矩阵的计算及特征值求解。

* **当前结果**: 模型成功找到了一个最佳投影方向（一条直线），旨在将两类样本投影后分得最开。但从可视化结果来看，该投影方向并不能将两类样本完美地线性分割，若基于此划分，依然会存在误分类点。

* **原因分析**:
    * 首先需要明确，LDA找到的直线是**最佳投影方向**，而非直接的分类边界。真正的分类边界是一条垂直于该方向的直线。
    * 效果不理想的根本原因与对数几率回归类似：西瓜数据集本身是**非线性可分**的，存在类别重叠。
    * LDA作为一种经典的**线性**降维与分类方法，其内在假设就是数据可以通过线性变换来区分。当数据本身不满足这个假设时，其分类效果自然会受限。

* **后续改进方向**:
    * **采用非线性判别分析**: 可以尝试使用更强大的判别分析模型，如能产生二次（曲线）决策边界的**二次判别分析 (QDA)**。
    * **采用其他非线性模型**: 与对数几率回归的改进方向一致，可以尝试支持向量机（SVM）、决策树、神经网络等模型来捕捉数据中的非线性结构。

### 决策树 (Decision Tree)

存放在 `decision_tree` 目录中，从零开始手动实现了决策树的核心算法，包括基于信息熵和基尼指数的划分策略，并实现了预剪枝和后剪枝功能。

* **当前结果**:
    * **未剪枝决策树**: 模型完全拟合了训练数据，生成了一棵结构较为复杂的决策树，但在7条验证集上的准确率仅为 **28.57%**，泛化能力很差。
    * **剪枝决策树**: 预剪枝与后剪枝均生成了同样简洁的决策树 (`{'色泽': {'乌黑': '是', '浅白': '否', '青绿': '是'}}`)。剪枝后，模型在验证集上的准确率显著提升至 **57.14%**。

* **原因分析**:
    * **过拟合问题**: 未剪枝决策树的验证集准确率极低，是典型的**过拟合(Overfitting)**现象。这说明模型学习了过多训练数据中的噪声和偶然规律，而没有抓住问题的本质，导致其在新样本（验证集）上表现不佳。
    * **剪枝的有效性**: 预剪枝和后剪枝都通过简化模型，成功提升了泛化能力。这证明了剪枝是防止决策树过拟合、提高模型实用性的关键步骤。
    * **与线性模型的对比**: 与对数几率回归和LDA不同，决策树作为一种**非线性模型**，其能力上限更高，能够捕捉到西瓜数据集中非线性的结构。剪枝的目的，正是在这种强大的非线性拟合能力与模型的泛化性之间找到一个更好的平衡。
    * **两种剪枝结果相同**: 在本次实验中，预剪枝和后剪枝得到了相同的结果。这通常说明数据集的结构相对清晰，预剪枝的“贪心”选择恰好与后剪枝的全局优化选择路径一致。在更复杂的数据集上，后剪枝通常能找到比预剪枝更优的平衡点。

* **后续改进方向**:
    * **集成学习模型**: 单棵决策树由于其不稳定性，性能上限有限。下一步的核心改进方向是使用基于决策树的**集成学习(Ensemble Learning)**模型。
        * **随机森林 (Random Forest)**: 通过构建多棵决策树并让其投票，可以显著提高模型的稳定性和准确率，进一步降低过拟合风险。
        * **梯度提升决策树 (GBDT)**: 如XGBoost、LightGBM等模型，通过迭代地构建新树来修正前面所有树的错误，是目前在处理表格数据任务中最强大、最主流的模型之一。